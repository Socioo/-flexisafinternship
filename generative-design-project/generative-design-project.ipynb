{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99d363a5-20bc-47b0-9b52-c54bda090ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Reshape, LeakyReLU, BatchNormalization, Conv2D, Flatten, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bf594e8-bf08-4180-9afc-9bf66e9274f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train / 127.5 - 1.0  # Normalize images to [-1, 1]\n",
    "X_train = np.expand_dims(X_train, axis=-1)  # Add channel dimension\n",
    "\n",
    "# Normalize and reshape the data\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5  # Rescale to [-1, 1]\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)  # Reshape to (28, 28, 1)\n",
    "\n",
    "X_test = (X_test.astype(np.float32) - 127.5) / 127.5  # Rescale to [-1, 1]\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)  # Reshape to (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09b6efee-c76d-49fb-adc9-4ceb71f9c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dense(28 * 28, activation='tanh'))\n",
    "    model.add(Reshape((28, 28, 1)))  # Reshape to 28x28 image\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "054fd986-fcba-4117-90fb-5e327b09d093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding='same', input_shape=(28, 28, 1)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67786143-926f-4878-9fdd-0e5681ab01c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False  # Freeze discriminator when training GAN\n",
    "    gan_input = Input(shape=(latent_dim,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "    gan = Model(gan_input, gan_output)\n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce59a8ca-34a8-4742-ac87-864b37aeeabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, gan, images, latent_dim, batch_size, epochs):\n",
    "    half_batch = batch_size // 2\n",
    "    for epoch in range(epochs):\n",
    "        # Train discriminator\n",
    "        idx = np.random.randint(0, images.shape[0], half_batch)\n",
    "        real_images = images[idx]\n",
    "        noise = np.random.normal(0, 1, (half_batch, latent_dim))\n",
    "        fake_images = generator.predict(noise)\n",
    "        \n",
    "        d_loss_real = discriminator.train_on_batch(real_images, np.ones((half_batch, 1)))\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_images, np.zeros((half_batch, 1)))\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        # Train generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        g_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "        \n",
    "        print(f\"{epoch}/{epochs} [D loss: {d_loss[0]} | D accuracy: {100*d_loss[1]}] [G loss: {g_loss}]\")\n",
    "        \n",
    "        # Display images every 1000 epochs\n",
    "        if epoch % 1000 == 0:  # Show every 1000 epochs\n",
    "            noise = np.random.normal(0, 1, (1, latent_dim))\n",
    "            generated_image = generator.predict(noise)\n",
    "            plt.imshow(generated_image[0, :, :, 0], cmap='gray')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d80eed00-fd77-46b3-97e3-49c4dd266c74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m image_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/Ahmadee/PycharmProjects/generative-design-project/data/raw_images\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mload_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m X_train \u001b[38;5;241m=\u001b[39m (images \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m127.5\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m127.5\u001b[39m\n\u001b[0;32m      4\u001b[0m X_train \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mastype (np\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m, in \u001b[0;36mload_images\u001b[1;34m(image_dir, target_size)\u001b[0m\n\u001b[0;32m      5\u001b[0m img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_dir, filename)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load image using OpenCV or Keras' image module\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mimread(img_path, cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Resize image to the desired target size (e.g., 28x28 for MNIST-like dataset)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, target_size)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "image_dir = 'C:/Users/Ahmadee/PycharmProjects/generative-design-project/data/raw_images'\n",
    "images = load_images(image_dir)\n",
    "X_train = (images - 127.5) / 127.5\n",
    "X_train = X_train.astype (np.float32)\n",
    "\n",
    "latent_dim = 100  # Latent dimension for random noise\n",
    "batch_size = 64\n",
    "epochs = 10000\n",
    "\n",
    "# Initialize the models\n",
    "generator = build_generator(latent_dim)\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "# Compile the models\n",
    "discriminator.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')\n",
    "\n",
    "# Train the GAN\n",
    "train_gan(generator, discriminator, gan, X_train, latent_dim, batch_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11a4b861-a8f5-4354-a696-9b1c864b1fd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# 2. Now, load the images (make sure to call this after the function is defined)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m image_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/Ahmadee/PycharmProjects/generative-design-project/data/raw_images\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 25\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mload_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# 3. Preprocess the images\u001b[39;00m\n\u001b[0;32m     28\u001b[0m X_train \u001b[38;5;241m=\u001b[39m images  \u001b[38;5;66;03m# This holds your loaded and processed images\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m, in \u001b[0;36mload_images\u001b[1;34m(image_dir, target_size)\u001b[0m\n\u001b[0;32m      5\u001b[0m img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_dir, filename)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load image using OpenCV or Keras' image module\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mimread(img_path, cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Resize image to the desired target size (e.g., 28x28 for MNIST-like dataset)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, target_size)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "def load_images(image_dir, target_size=(28, 28)):\n",
    "    images = []\n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(image_dir):\n",
    "        img_path = os.path.join(image_dir, filename)\n",
    "        \n",
    "        # Load image using OpenCV or Keras' image module\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Resize image to the desired target size (e.g., 28x28 for MNIST-like dataset)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        \n",
    "        # Normalize the image to [-1, 1] range and reshape\n",
    "        img = (img.astype(np.float32) - 127.5) / 127.5\n",
    "        img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
    "        \n",
    "        images.append(img)\n",
    "    \n",
    "    # Convert list to numpy array\n",
    "    images = np.array(images)\n",
    "    return images\n",
    "\n",
    "# 2. Now, load the images (make sure to call this after the function is defined)\n",
    "image_dir = 'C:/Users/Ahmadee/PycharmProjects/generative-design-project/data/raw_images'\n",
    "images = load_images(image_dir)\n",
    "\n",
    "# 3. Preprocess the images\n",
    "X_train = images  # This holds your loaded and processed images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
